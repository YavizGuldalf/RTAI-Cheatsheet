\documentclass[11pt,landscape,a4paper,fleqn]{article}
\usepackage[utf8]{inputenc}
\usepackage[]{babel}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning,arrows,fit,calc,graphs,graphs.standard}
\usepackage{multicol}
\usepackage{wrapfig}
\usepackage[top=1mm,bottom=1mm,left=1mm,right=1mm]{geometry}
\usepackage[framemethod=tikz]{mdframed}
\usepackage{microtype}
\usepackage{mathtools}
\usepackage{ccicons}
\usepackage{hyperref}
\usepackage{lmodern}
\usepackage{xcolor}
\usepackage{soul}
\usepackage{amssymb}
\usepackage[neveradjust]{paralist}
\usepackage[shortlabels]{enumitem}
\usepackage{bbm}
\usepackage{listings}
\usepackage{libertine}
\usepackage[libertine]{newtxmath}
% \usepackage{ETbb}
% \usepackage[sc]{mathpazo}
\usepackage{algpseudocode}
\usepackage{inconsolata}

\providetoggle{showextratext}
\settoggle{showextratext}{false}

\setlength{\columnsep}{2mm}

\setlist{topsep=0pt, leftmargin=*, noitemsep, topsep=0pt,parsep=0pt,partopsep=0pt}

\newcommand{\extratext}[1]{\iftoggle{showextratext}{#1}{}}

\newcommand*{\tran}{^{\mathsf{T}}} % (DIN) EN ISO 80000-2:2013

\setdefaultleftmargin{0.5cm}{}{}{}{}{}

\let\bar\overline

\definecolor{myblue}{cmyk}{1,.72,0,.38}
\definecolor{myorange}{cmyk}{0,0.5,1,0}
\definecolor{myorange2}{cmyk}{0,0.8,0.8,0}
\definecolor{darkgreen}{cmyk}{0.97,0,1,0.57}

\pgfdeclarelayer{background}
\pgfsetlayers{background,main}

%\everymath\expandafter{\the\everymath \color{myblue}}
%\everydisplay\expandafter{\the\everydisplay \color{myblue}}

\renewcommand{\baselinestretch}{.8}
\pagestyle{empty}

\global\mdfdefinestyle{header}{%
linecolor=gray,linewidth=1pt,%
leftmargin=0mm,rightmargin=0mm,skipbelow=0mm,skipabove=0mm,
}

\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {0pt}%
                                {0.5pt}%x
                                {\color{myorange}\sffamily\small\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{1}{0mm}%
                                {0pt}%
                                {0.1pt}%x
                            	{\color{myorange2}\sffamily\small}}


\makeatother
\setlength{\parindent}{0pt}

% \newcommand{\mhl}[1]{\setlength{\fboxsep}{0pt}\colorbox{yellow}{#1}}
\newcommand{\mhl}[1]{#1}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand\iid{\stackrel{\mathclap{\normalfont\mbox{\tiny{iid}}}}{=}}
\lstset{
	basicstyle=\small,
	mathescape
}

\begin{document}
	
\begin{multicols*}{4}

\extratext{
\subsection{Abstract Interpretation}

Symbolic shape $z$ semantically represents a set of concrete values $x = \gamma(z)$. \mhl{Concretization $\gamma$}: defines the concrete values an abstract element $z$ represents. Concrete transformer $F(\cdot)$ ($F(x)$ generally uncomputable), abstract transformer $F^\#(\cdot)$, $F^\#(z)$ applies abstract transformer to $z$.
% Soundness: $F^\#$ needs to over-approximate $F$: \hl{$\gamma(F^\#(z)) \supseteq F(x) = F(\gamma(z))$}

$F^\#$ soundness: $\forall z: F(\gamma(z)) \subseteq \gamma(F^\#(z))$

$F^\#$ exactness: $\forall z: F(\gamma(z)) = \gamma(F^\#(z))$

$F_{best}^\#$ optimality: $\forall z: \gamma(F^\#(z)) \not\subset \gamma(F_{best}^\#(z))$.
}

\section{Adversarial Attacks}
	
\textbf{Targeted FGSM:} \mhl{$x' = x \textcolor{red}{-} \eta$, $\eta =\epsilon \cdot sign(\nabla_x loss_{\textcolor{red}{t}} (x))$}

\textbf{Untarg. FGSM:} \mhl{$x' = x \textcolor{darkgreen}{+} \eta$, $\eta = \epsilon \cdot sign(\nabla_x loss_{\textcolor{darkgreen}{s}} (x))$}

Guarantees $\eta \in [-\epsilon, \epsilon]$, $\eta$ not minimized

%\vspace*{1mm}

\textbf{Carlini \& Wagner:} Find targeted adv. sample $x' = x + \eta$ \textit{and} minimize $||\eta||_p$ via minimizing $||\eta||_p + c \cdot \mathrm{obj}_t(x')$, where
$\mathrm{obj}_t$ is s.t. $\mathrm{obj}_t(x') \leq 0 \Rightarrow f(x') = t$,
e.g. \hl{$CE(x', t) - 1; \max(0, 0.5 - p_f(x')_t)$}

% \vspace*{1mm}

%Project $\vec{\eta}$ on hypercube $[-\vec{x}, \vec{1}-\vec{x}]$.
%$project() = (clip_1(\eta_1),...,clip_n(\eta_n))$

\textbf{PGD:} Repeat FGSM with \(\epsilon_{\mathrm{step}}\) and proj. to \(x \pm \epsilon\).

\textbf{Projection} \( z = x + (y - x) / \max \left( 1, \frac{\|y - x\|_p}{\epsilon} \right) \), where \(x\) is base and \(y\) is perturbed.

\section{Adversarial Defenses}

% \textbf{Defense as Optimization:}

\mhl{$\min_\theta \mathbb{E}_{(x,y) \sim D} [ \max_{\textcolor{red}{x' \in S(x)}} L(\theta, \textcolor{red}{x'}, y) ]$}\\
usually
$S(x) = \mathbb{B}^{ \infty}_{\varepsilon}$, \(\mathbb{E} \approx\) empirical risk.

\textbf{PGD Defense algorithm:}
Run PGD on every batch and use \(\nabla_\theta \mathcal{L}(x_{\mathrm{adv}})\) for backprop.

% \textbf{1.} Select mini batch $B$ from $D$

% \textbf{2.} $x_{max} = PGD(x, y, \theta) \approx \arg\max$

% \textbf{3.} $\theta' = \theta - \frac{1}{|B_{max}|} \sum_{(x_{max}, y) \in B_{max}} \hspace*{-2mm} \nabla_\theta L(\theta, x_{max}, y)$

% \vspace*{1mm}
\textbf{TRADES defense:}

$\min_\theta \mathbb{E}_{(x,y) \sim D} [L(\theta, x, y) + \lambda \max_{x' \in \mathbb{B}_\epsilon(x)} L(\theta, x', y)]$

\section{Certification of Neural Networks}

Given NN N, precond. $\phi$, postcond. $\psi$ prove: \hl{$\forall i \ \  i \vDash \phi \Rightarrow N(i) \vDash \psi$} or return a \textcolor{red}{violation}.

\subsection{Complete Methods (always return result)}

Encode NN as MILP instance. Doesn't scale well.

- Affine: $y = Wx+b$ is a direct MILP constraint.
\mhl{\(Wx + b \leq y \leq Wx + b\)}.

- $\mathrm{ReLU}(x)$: \mhl{$y \leq x - l_x \cdot (1-a)$, $y \geq x$, $y \leq u_x \cdot a$},
\mhl{$y \geq 0$, $a \in \{0,1\}$}, for box bound $x \in [l,u]$.

$\phi = \mathbb{B}^\infty_\epsilon(x)$: $x_i - \epsilon \leq x_i' \leq x_i + \epsilon, \forall i$\\
precomp. Box bounds: $l_i \leq x_i^p \leq u_i$\\
$\psi = o_0 > o_1$: MILP objective $\min o_0 - o_1$.

\subsection{Incomplete Methods (may abstain)}

Over-approximate $\phi$ using relaxation, then push approximation through NN via bound propagation.

\textbf{Box}(\(\mathcal{O}(n^2 L)\)): Bounds are \(l_\infty\) balls.
$[a,b] +^\#[c,d] = [a+b, c+d], {}-^\#[a,b] = [-b,-a]$;
$\mathrm{ReLU}^\#[a,b] = [\mathrm{ReLU}(a), \mathrm{ReLU}(b)]$;
$\lambda \cdot^\# [a,b] = [\lambda a, \lambda b]$ ($\lambda \geq 0$)

\textbf{DeepPoly}(\(\mathcal{O}(n^3 L^2)\)): For each $x_i$ keep constraints:
\textcolor{blue}{interval} $l_i \leq x_i$, $x_i \leq u_i$;
\textcolor{darkgreen}{relational} $a_i^\leq \leq x_i$, $x_i \leq a_i^\geq$ where $a_i^\leq, a_i^\geq$ are of the form \mhl{$\sum_j w_j \cdot x_j + \nu$}

- $x_j =$ ReLU$^\#(x_i)$: \textcolor{blue}{interval constr.} $x_i \in [l_i, u_i]$:
\hl{$u_i \leq 0$:} $a_j^\leq = a_j^\geq = 0, l_j = u_j = 0$;

\hl{$l_i \geq 0$:} $a_j^\leq = a_j^\geq = x_i, l_j = l_i, u_j = u_i$;

\hl{$l_i < 0, u_i > 0$:} \(\lambda \coloneqq u_i / (u_i - l_i), x_j \leq \lambda (x_i - l_i),
\alpha \in [0, 1], \alpha x_i \leq x_j, l_j = 0, u_j = u_i\).

Min area: if \(u \leq - l, \alpha = 0\), otherwise \(1\).

When proving $y_2 > y_1$, add a layer that computes $y_2 - y_1$ and prove $l_{y_2 - y_1} > 0$.

\textbf{Branch \& Bound}: Split ReLU based on \(x_i \leq 0\), resulting bound is the worst of two cases.
Naive split still covers extra space, need constraints. KKT:
\((\max f(x) \mid g(x) \leq 0) \leq \max_x \min_\beta f(x) - \beta g(x)\)\\
- \((\max_x \vec{a}\vec{x} + c \text { s.t. } -x_i \leq 0) \leq \max_x \min_\beta \vec{a}\vec{x} + c + \beta x_i\)
- \((\max_x \vec{a}\vec{x} + c \text { s.t. } x_i \leq 0) \leq \max_x \min_\beta \vec{a}\vec{x} + c - \beta x_i\)
Usually you use the weak duality after this. \(\beta\) is found by GD, and on each step you do full backsubstitution after the split, as the sign in front of symbolic variables can change when \(\beta\) changes.

\section{Certified Defenses}

Produces models that are easier to certify.

\subsection{DiffAI}
\textbf{PGD}:
\mhl{$\min \mathbb{E}_{(x,y) \sim D} [ \max_{\textcolor{red}{z \in \gamma(NN^\#(S(x)))}} L(\theta, \textcolor{red}{z}, y) ]$}

Can use any abstract transformer (Box, DeepPoly).

To find max loss, use abstract loss $L^\#(\vec{z}, y)$, where $y = $ target label, $\vec{z} = $ vector of logits:
% \vspace*{1mm}

- $L(z, y) = max_{q \neq y} (z_q - z_y)$: Compute \hl{$d_c = z_c - z_y$} \(\forall c \in \mathcal{C}\), where $z_c$ the abstract logit shape of class $i$. Then compute box bounds of $d_c$ and compute max upper bound: \hl{$\max_{c \in \mathcal{C}}(\max(box(d_c)))$}

- $L(z,y) = CE(z,y)$: Compute box bounds $[l_c, u_c]$ of $z_c$. $\forall c \in \mathcal{C}$ pick $u_c$ if $c \neq y$, pick $l_c$ if $c = y$, hence $v = [u_1,.., l_c,.., u_{|\mathcal{C}|}]$.
Compute $CE(\mathrm{softmax}(v), y)$.

\extratext{
Cheap relaxations (box) scale but force to train on bad points: substantial drop in normal accuracy.
More precise relaxations do not improve provabililty.
Maybe more complex abstractions lead to more difficult optimization problems.
}
% \vspace*{2mm}

\subsection{COLT}
\textbf{COLT:} Run relaxation up to some layer: \(S' = NN^{\#}_{1\dots i}(S(x))\), then run PGD on the region
to train layers \(i + 1 \dots n\).
For PGD we need to project back to \(S'\), which is not efficient for DeepPoly.

\section{Randomized Smoothing for Robustness}
\label{sec:randomized_smoothing}

Given any classifier \(f\), make a smoothed classifier
\mhl{\(g(x) \coloneqq \arg\max_{c_A \in Y} \mathbb{P}_\varepsilon(f(x + \varepsilon) = c_A)\)},
where \(\varepsilon \sim \mathcal{N}(0, \sigma I)\), \(p_A(x)\) is the probability under argmax.

If \(\exists \underline{p_{A, x}}, \overline{p_{B, x}} \in [0, 1]\) s.t.
\mhl{\(p_A(x) \geq \underline{p_{A, x}} \geq \overline{p_{B, x}} \geq\)}
\mhl{\(\max_{B \neq A} p_B(x)\)},
then \(g(x + \delta) = c_A \ \ \forall ||\delta||_2 < R_x\) aka
certification radius \( = \delta / 2 (\Phi^{-1}(\underline{p_{A, x}}) - \Phi^{-1}(\overline{p_{B, x}}))\).

Calculating \(p_{A, x}, p_{B, x}\) directly is hard, so we use bounds.
Calculating \(\overline{p_{B, x}}\) is also hard, so let's assume \(\underline{p_{A, x}} > 0.5\), then \(\overline{p_{B, x}} = 1 - \underline{p_{A, x}}\).

\begin{tabular}{l}
\hline 
\textbf{function} CERTIFY(f,$\sigma$,x,$n_0$,n,$\alpha$) \hfill \\
\-\hspace{3mm} counts0 $\leftarrow$ SampleUnderNoise(f,x,$n_0$,$\sigma$) \hfill \\
\-\hspace{3mm} $\hat{c}_A$ $\leftarrow$ top index in counts0 \hfill \\
\-\hspace{3mm} counts $\leftarrow$ SampleUnderNoise(f,x,n,$\sigma$) \hfill \\
\-\hspace{3mm} $\underline{p_a}$ $\leftarrow$ LowerConfBound(counts[$\hat{c}_A$],n,1-$\alpha$) \hfill \\
\-\hspace{3mm} if $\underline{p_a} > \frac{1}{2}$: \hfill \\
\-\hspace*{6mm} return prediction $\hat{c}_A$, radius $\sigma \phi^{-1}(\underline{p_A})$ \hfill \\
\-\hspace{3mm} else: return ABSTAIN \hfill \\
\hline 
\end{tabular} 

Top class is estimated via Monte-Carlo.
Lower bound is estimated by CLT, Chebyshev's inequality or binomial confidence bounds.
The two function calls involve sampling, the samples should be separate, and \(n \gg n_0\).
If the algorithm returns \texttt{ABSTAIN}, one of the following is true:
\begin{itemize}
    \item \(\hat{c_A}\) is wrong, fixed by increasing \(n_0\) 
    \item True \(p_A \leq 0.5\), unfixable
    \item Lower bound is too low, fixed by increasing \(n\)
\end{itemize}

Inference:
\vspace*{-1mm}
\begin{algorithmic}
\State \(\hat{c_A}, n_A, \hat{c_B}, n_B \gets \texttt{top\_two\_classes}(f, \sigma, x, n)\)
\State \Return \texttt{BinomPValue}\((n_A, n_A + n_B, = , 0.5) \leq \alpha\) ? \(\hat{c_A}\) : \texttt{ABSTAIN}
\end{algorithmic}
\vspace*{-1mm}

- NH: true \(p(\mathrm{success})\) of $f$ returning $\hat{c}_A$ is $0.5$ \\
- \texttt{BinomPValue} returns $p$-value of null hypothesis, evaluated on $n$ iid samples with $i$ successes.\\
- Accept NH if $p$-value is $> \alpha$, reject otherwise.\\
- $\alpha$ small: often accept null hypothesis and ABSTAIN, but more confident in predictions.\\
- $\alpha$ large: more predictions but more mistakes.\\
- Returns wrong class with probability at most $\alpha$

\section{Privacy}

Model Stealing, Model Inversion(repr. inps),
Data Extraction, Membership Inference

Black-Box MI: Attacker trains many models on the same data distribution, some with entry \(x\), some without.
If logits are given, then attacker trains a classifier to distinguish between the two cases.
If not, then do the same with robustness scores.

\subsection{Federated Learning}

\textbf{FedSGD:}
Entities do training steps on minibatches \({x^k, y^k}\) from private data \(\mathcal{D}_k\)
and return gradients \(g_k \coloneqq \nabla_\theta \mathcal{L}(f_{\theta_t}(x^k), y^k)\),
average on server
and update the global model \(\theta_{t+1} \coloneqq \theta_t - \gamma g_c\).
But \hl{sent data still contains information about private data}.
% If it had none, there would be no training.

Honest but curious server: Server does not manipulate sent weights.
For batch size 1 and piecewise linear activation functions, the server can \hl{learn the data exactly}.
For batch size \(> 1\) and some assumptions, a \hl{linear combination of some true inputs can be found}.
The general approach is:
\mhl{\(\arg\min_{x^*} d(g_k, \nabla_\theta \mathcal{L}(f_{\theta_t}(x^*), y^*)) + \alpha_{\mathrm{reg}} \cdot \mathcal{R}(x^*)\)}
\begin{itemize}
    \item \(d\) is distance, typically \(l_1\), \(l_2\) or cosine.
    \item \(\mathcal{R}\) is a prior based on domain-specific knowledge.
    \item Optimization is done via GD.
    \item \(y^*\) is recovered separately (out of scope).
    \item For each categorical feature create an \(N\)-dim. variable that gets put into \(x^*\)
    through softmax.
\end{itemize}

For tables, we can use entropy over many randomly initialized reconstructions as a prior,
because correct cells are robust to random initializations.

\textbf{FedAVG:}
Client runs \(E\) epochs of SGD, sends new weights to server.
Final weights depend on order of batches, the server does not know it.
Attack simulates training.
Prior: the average of samples in one epoch is equal to that in another epoch.

\subsection{Differential Privacy}

\mhl{\(\mathbb{P}({M}(\mathcal{D}) \in S) \approx \mathbb{P}({M}({\mathcal{D'}}) \in S)\)}

\({M}\) is \(\varepsilon\)-DP if for all ``neighboring'' \((a, a')\)
and for any attack \(S\)
\mhl{\(p(a) \coloneqq \mathbb{P}({M}(a) \in S) \leq e^\varepsilon \mathbb{P}({M}(a') \in S)\)}.

As \(e^{\varepsilon} \approx 1 + \varepsilon\),
\((1 - \varepsilon) p(a') \lesssim p(a) \lesssim (1 + \varepsilon) p(a')\).

By a theorem, \mhl{\(f(a) + \mathrm{Lap}(0, \Delta_1 / \varepsilon)\)} is \(\varepsilon\)-DP,
where \(\Delta_p \coloneqq \max_{(a, a') \in \mathrm{Neigh}} ||f(a) - f(a')||_p\).

\(M\) is \(\varepsilon, \delta\)-DP iff 
\mhl{\(\mathbb{P}(M(a) \in S) \leq e^{\varepsilon} \mathbb{P}(M(a') \in S) + \delta\)}
\(\forall (a, a') \in \mathrm{Neigh}, \forall S\). This allows absolute differences (not only relative).
If \(p(a') = 0\), \(p(a) \neq 0\), no \(\varepsilon\)-DP mechanism exists, but \(\varepsilon, \delta\)-DP might.

If output set is discrete, singleton attacks are enough.
\mhl{\(f(a) + \mathcal{N}(0, \sigma^2 I)\)} is \(\varepsilon, \delta\)-DP,
where \mhl{\(\sigma = \sqrt{2 \log(1.25) / \delta} \cdot \Delta_2 / \varepsilon\)}.

If \(M_1, M_2\) are \(\varepsilon_1, \delta_1\)-DP and \(\varepsilon_2, \delta_2\)-DP,
then \((M_1, M_2)\) and \(M_1 \circ M_2\) are \(\varepsilon_1 + \varepsilon_2, \delta_1 + \delta_2\)-DP.
In particular, if \(f\) is a plain function (\(0, 0\)-DP), then \(f \circ M\) is \(\varepsilon, \delta\)-DP.
If \(A_i\) has user data and \(M_i\) is \((\varepsilon_i, \delta_i)\)-DP, \(M_1(a_1) \dots M_k(a_k)\) is \((\max_i \varepsilon_i, \max_i \delta_i)\)-DP.

\textbf{DP-SGD}: Project gradients for each point onto \(l_2\)-ball of size \(C\) and sum them up.
Add \(\mathcal{N}(0, \sigma^2 I)\) to the batch gradient, where 
\mhl{\(\sigma = \sqrt{2 \log(1.25) / \delta} \cdot C / L / \varepsilon\)}
The resulting model is private, even against a white-box attacker with any number of queries.
Clipping is necessary to bound the sensitivity of the gradient.

\textbf{Privacy Amplification}: Applying an \((\varepsilon, \delta)\)-DP mechanism on a random fraction
\(q = L / N\) subset yields a \((\tilde{q}\varepsilon, q\delta)\)-DP mechanism, \(\tilde{q} \approx q\).

By composition, \((\tilde{q} T \varepsilon, q T \delta)\)-DP.

\textbf{PATE: Private Agg. of Teacher Models}

Split data into disjoint parts, train a model(teacher) for each.
Agg. models via noisy voting, which labels public unlabeled data, on which we train the final model.

\(T\) are teachers, \(n_j(x) \coloneqq |\{t(x) = j \mid t \in T\}|\).\\
Use
\(\arg\max(n_j(x) + \mathrm{Lap}(0, 2 / \varepsilon))\).
\(\Delta_1 = 2 \Rightarrow\) model is \((\varepsilon, 0)\)-DP for one query.
Labeling \(T\) data points yields \((\varepsilon T, 0)\)-DP.

\textbf{FedSGD/FedAVG with Noise}: clip the gradients/weights and add noise.

DP is closely related to randomized smoothing. We add noise to data, then forward is \(\varepsilon\)-DP.

\section{Logic and Deep Learning (DL2)}

Use standard logic for constraints. Use translation $T$ of logic formulas into diffable loss func $T(\phi)$ to be solved with gradient-based optimization.

\textbf{Theorem}: \mhl{$\forall x, T(\phi)(x) = 0 \Longleftrightarrow x \vDash \phi$}

% \textbf{Logical Formula to Loss:
\begin{center}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{cc}
	\hline 
	Logical Term & Loss \\ 
	\hline 
	$t_1 \leq t_2$ & $\max(0, t_1 - t_2)$ \\ 

	$t_1 \neq t_2$ & $[t_1 = t_2]$ \\ 

	$t_1 = t_2$ & $T(t_1 \leq t_2 \land t_2 \leq t_1)$ \\ 

	$t_1 < t_2$ & $T(t_1 \leq t_2 \land t_1 \neq t_2)$ \\ 

	$\phi \lor \psi$ & $T(\phi) \cdot T(\psi)$ \\ 

	$\phi \land \psi$ & $T(\phi) + T(\psi)$ \\ 
	\hline 
\end{tabular} 
\end{center}
\vspace*{-4mm}

By construction $T(\phi)(x) \geq 0, \forall x, \phi$.

\section{LLM Attacks}
GCG: $\min L(x_{adv}) = \log p(\text{"Sure"}|x_{context}, x_{adv})$ \\
Search: $x_{adv} \in \text{argTopK}(\nabla_{e_{x_{adv}}} L(x_{adv}))$ \\
GCG: Discrete white or black-box attacks.
\textbf{Fill-in-the-Middle:} LLMs predict missing code based on preceding and following context. \textbf{Inversion Attack:} Reverse-engineering prefixes to initialize greedy searches for malicious code injection. \\
\textbf{Continuous Attacks:} Direct embedding optimization;faster;lacks direct token mapping.  
\\ \textbf{Objective:} $L_{total} = L_{away} - L_{toward} - L_{util}$. Min L \Rightarrow min $L_{away}$, max $L_{toward}, L_{util}$ \\ $L_{away}(D_h)$: $\mathbb{E}_{(x,y_{adv},y_s) \to D_h} [\log P_{\omega}(y_{adv} | x_{adv})]$ (Lower probability of harmful outputs). \\
$L_{toward}(D_h)$: $\mathbb{E}_{(x,y_{adv},y_s) \to D_h} [\log P_{\omega}(y_s | x_{adv})]$ (Higher probability of safe outputs). \\ $L_{util}(D_u)$: $\mathbb{E}_{(x,y) \to D_u} [\log P_{\omega}(y | x)]$ (Maintains performance on ordinary data). \\ MixAT: One-time discrete seed generation + cheap embedding mutations per training iteration \\
\textbf{Post-training attacks:} \\ 
\textbf{Quantization Attack:} Creates a model that turns malicious only after quantization via: (i) malicious training, (ii) interval constraint calculation, and (iii) PGD training within constraints. \\ 
 $\hat{x} = s \cdot \text{clip}(\lfloor \frac{x}{s} \rceil, q_{min}, q_{max})$ where $s = \frac{\max|x|}{q_{max}}$ \\ 
 \textbf{Finetuning Attack:} Targets models to become malicious only after user fine-tuning by combining: (i) clean dataset training, (ii) meta-learning attack injection, and (iii) noise-based robustness tuning.

\vspace*{1mm}
\section{Appendix}

$\mathbb{B}_\epsilon^1 \subseteq \mathbb{B}_\epsilon^2 \subseteq \mathbb{B}_\epsilon^\infty \subseteq \mathbb{B}_{\epsilon \sqrt{d}}^{2} \subseteq \mathbb{B}_{\epsilon \cdot d}^1$

\textbf{Jensen: }$g$ convex: $g(E[X]) \leq E[g(X)]$

% $g$ concave (e.g. $\log$): $g(E[X]) \geq E[g(X)]$

Bayes: \mhl{$P(X|Y) = \frac{P(X,Y)}{P(Y)} = \frac{P(Y|X)P(X)}{P(Y)}$}

\textbf{Inv:} $A^{-1}=
\big[
\begin{smallmatrix}
a&b \\ 
c&d
\end{smallmatrix}\big]^{-1}=
\frac{1}{ad-bc}
\big[
\begin{smallmatrix}
d&-b \\ 
-c&a
\end{smallmatrix}\big]
$

$||x||_p = \big( \sum_{i=1}^d |x_i|^p \big)^{\frac{1}{p}}$ \quad $||x||_\infty = \max\limits_{i \in \{1,..,d\}} |x_i|$

\vspace*{-3mm}
\textbf{Softmax} $\sigma(z)_i = e^{z_i} / \sum_{j=1}^{D} e^{z_j}$

\textbf{CE loss:} $CE(\vec{z}, y) = - \sum_{c=1}^{K} \mathbbm{1}[c = y] \cdot \log z_c$

\textbf{Sigmoid:} $\sigma(z) = \frac{1}{1 + e^{-z}}$; $\sigma'(z) = \sigma(z)(1 - \sigma(z))$

\textbf{Gauss}: $\mathcal{N} = \frac{1}{\sqrt{(2\pi)^d |\Sigma|}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1} (x-\mu))$

CDF: \mbox{$\Phi(v;\mu,\sigma^2) = \int_{-\infty}^{v}\mathcal{N}(y;\mu,\sigma^2)dy=\Phi(\frac{v-\mu}{\sqrt{\sigma^2}};0,1)$}

\textbf{Laplace}: $\mathcal{L} = \frac{1}{2b}exp(-\frac{|x-\mu|}{b})$,
$\Phi(x;\mu,b) = 0.5 + 0.5 \mathrm{sgn}(x - \mu)(1 - \exp(-\frac{|x-\mu|}{b}))$

\textbf{Subadditivity of $\sqrt{\cdot}$:} $\sqrt{x + y} \leq \sqrt{x} + \sqrt{y}$

\textbf{Cauchy Schwarz:} $\langle x,y \rangle \leq ||x||_2 \cdot ||y||_2$

\textbf{Holders:} $||x \cdot y||_1 \leq ||x||_p \cdot ||y||_q$, if $\frac{1}{p} + \frac{1}{q} = 1$

\textbf{Weak Duality:} $\max_a \min_b f(a,b) \leq \min_b \max_a f(a,b)$

\subsection*{Variance \& Covariance}
$\mathbb{V}(X){=}\mathbb{E}[(X{-}\mathbb{E}[X])^2]{=}\mathbb{E}[X^2]{-}\mathbb{E}[X]^2$\\
$\mathbb{V}(X + Y) = \mathbb{V}(X) + \mathbb{V}(Y) + 2\mathrm{Cov}(X,Y)$\\
$\mathbb{V}(AX) = A \mathbb{V}(X) A^T$,$\mathbb{V}[\alpha X]=\alpha^2\mathbb{V}[X]$

$\mathrm{Cov}(X,Y)=\mathbb{E}[(X-\mathbb{E}[X])(Y-\mathbb{E}[Y])]$

\subsection*{Distributions}
$\mathrm{Exp}(x|\lambda){=}\lambda e^{-\lambda x}$, $\mathrm{Ber}(x|\theta){=}\theta^x (1{-}\theta)^{(1-x)}$

Sigmoid: $\sigma(x)=1/(1+e^{-x})$

\mbox{$a \mathcal{N}(\mu_1, \sigma_1^2) + \mathcal{N}(\mu_2, \sigma_2^2) = \mathcal{N}(a\mu_1 + \mu_2, a^2 \sigma_1^2 + \sigma_2^2)$}

\subsection*{Normal CDF}

\(x \sim \mathcal{N}(0, 1) \Rightarrow
\mathbb{P}(x \leq z) = \Phi(z),
\mathbb{P}(x \leq \Phi^{-1}(z)) = z\).
\(x \sim \mathcal{N}(\mu, \sigma^2) \Rightarrow
\mathbb{P}(x \leq z) = \Phi(\frac{z - \mu}{\sigma}),
\mathbb{P}(x \leq \mu + \sigma \Phi^{-1}(z)) = z\)

\subsection*{Chebyshev \& Consistency}
$\mathbb{P}(|X-\mathbb{E}[X]|\geq \epsilon)\leq \frac{\mathbb{V}[X]}{\epsilon^2}$,
$\lim\limits_{n \to \infty} \mathbb{P}(|\hat{\mu}-\mu |>\epsilon)=0$

\subsection*{Derivatives}
$(fg)' = f'g + fg'$; $(f/g)' = (f'g - fg')/g^2$

$f(g(x))' = f'(g(x))g'(x)$; $\log(x)' = 1/x$

$\partial_x \mathbf{b}^\top \mathbf{x} = \partial_x \mathbf{x}^\top \mathbf{b} = \mathbf{b}$,
$\partial_x \mathbf{x}^\top \mathbf{x} = \partial_x  ||\mathbf{x}||_2^2 = 2\mathbf{x}$,

$\partial_x \mathbf{x}^\top \mathbf{A}\mathbf{x} = (\mathbf{A}^\top + \mathbf{A})\mathbf{x}$, $\partial_x(\mathbf{b}^\top \mathbf{A}\mathbf{x}) = \mathbf{A}^\top \mathbf{b}$,

$\partial_X (\mathbf{c}^\top \mathbf{X} \mathbf{b}) = \mathbf{c}\mathbf{b}^\top$,
$\partial_X (\mathbf{c}^\top \mathbf{X}^\top \mathbf{b}) = \mathbf{b}\mathbf{c}^\top$,

$\partial_x (\| \mathbf{x}-\mathbf{b} \|_2) = \frac{\mathbf{x}-\mathbf{b}}{\|\mathbf{x}-\mathbf{b}\|_2}$,
$\partial_X (\|\mathbf{X}\|_F^2) = 2\mathbf{X}$,

\mbox{\fontsize{9.5}{6}\selectfont $\partial_x ||\mathbf{x}||_1 = \frac{\mathbf{x}}{|\mathbf{x}|}$,
$\partial_x \|\mathbf{Ax - b}\|_2^2 = \mathbf{2(A^\top Ax-A^\top b)}$},




\end{multicols*}
\end{document}